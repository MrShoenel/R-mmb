<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Hyperparameter Evaluation • mmb</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Hyperparameter Evaluation">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">mmb</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.11.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Hyperparameter-Evaluation.html">Hyperparameter Evaluation</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Hyperparameter Evaluation</h1>
                        <h4 class="author">Sebastian Hönel</h4>
            
            <h4 class="date">2020-03-10</h4>
      
      
      <div class="hidden name"><code>Hyperparameter-Evaluation.rmd</code></div>

    </div>

    
    
<blockquote>
<p>This vignette only embeds a rendered version of another <code>R</code> notebook, that evaluates the effect of hyperparameters of all functions used for inferencing in the package <strong><code>mmb</code></strong>. It should be displayed right below this paragraph. If you have trouble viewing it, check out the latest version on Github: <a href="https://mrshoenel.github.io/R-mmb/articles/hyperparameters.html">Hyperparameter Evaluation</a>. Additional formats are available here: <a href="https://github.com/MrShoenel/R-mmb/tree/master/eval/">Additional Formats</a>.</p>
</blockquote>
<hr>
<p>Functions implemented in <strong><code>mmb</code></strong> support some hyperparameters. This notebook evaluates them and compares performance to other well-known methods, using some well-known methods. The results of this notebook are included in the vignette <em>Hyperparameter Evaluation</em>. Since this is a rather substantial analysis, it cannot be a vignette itself, and is built externally.</p>
<div id="grid-search" class="section level1">
<h1 class="hasAnchor">
<a href="#grid-search" class="anchor"></a>Grid search</h1>
<p>In the first section, we are evaluating our new classifier and regressor for some well known datasets, using a grid-search approach and <code>caret</code>. We start with classification, then continue with regression. Those best parameters will then be used in further comparisons against other models.</p>
<p>In the following block, we can globally disable attempts to compute results. If the resulting files are present, then the related evaluations are skipped anyway. However, setting the following to FALSE, will prevent the actual attempt.</p>
<pre><code>DISABLE_COMPUTATIONS &lt;- TRUE</code></pre>
<p>Let’s first install all the needed packages:</p>
<p>First, define the models we want to test:</p>
<pre><code># Used by both regression and classification!
caret_models &lt;- c(
  "null", "bayesCaret", "ranger", "gbm", "mlpML", "bayesglm")

# This is extra models used for classification/regression resp.:
caret_models_c &lt;- c(caret_models,
  "pam", "naive_bayes", "C5.0", "rda")
caret_models_r &lt;- c(caret_models,
  "knn", "pcr", "kernelpls", "rpart2")</code></pre>
<p>We define a couple of helper-functions:</p>
<pre><code># We will truncate all datasets to this amount if larger using
# appropriate resampling!
max_rows_dataset &lt;- 2000


#' Unifies the way we retrieve a dataset. Already splits the dataset
#' into training- and validation partitions. The split is 0.7, if the
#' amount of rows is less than 800; 0.85, otherwise.
#' @param name a short-cut name of the dataset to obtain, e.g. "iris"
#' @param seedMult an integer used for \code{set.seed()}
#' @param useDs an optional data.frame of a 3rd party dataset. Use this
#' to use your own dataset but still obtain a list as produced by this
#' function.
#' @param useLabel character the name of the label to use when passing
#' in an own dataset using 'useDs'.
#' @return list with the entries 'ds' (the entire dataset as data.frame),
#' 'label' (name of column to be the label/target), 'train' and 'valid'
#' (data.frames with training and validation data; train+valid = ds)
get_dataset &lt;- function(name, seedMult, useDs = NULL, useLabel = NULL) {
  set.seed((0xceed * seedMult * max_rows_dataset) %% .Machine$integer.max)
  
  ds &lt;- NULL
  dsLabel &lt;- "Class"

  if (name == "chick") {
    data("ChickWeight")
    ds &lt;- data.frame(ChickWeight)
    dsLabel &lt;- "Diet"
  } else if (name == "iris") {
    data("iris")
    ds &lt;- iris
    dsLabel &lt;- "Species"
  } else if (name == "credit") {
    data("GermanCredit")
    ds &lt;- data.frame(GermanCredit)[, 1:10]
  } else if (name == "glass") {
    data("Glass")
    ds &lt;- data.frame(Glass)
    dsLabel &lt;- "Type"
  } else if (name == "breast") {
    data("BreastCancer")
    ds &lt;- data.frame(BreastCancer)
    
    ds$Id &lt;- NULL
    ds$Cl.thickness &lt;- as.integer(ds$Cl.thickness)
    ds$Cell.size &lt;- as.integer(ds$Cell.size)
    ds$Cell.shape &lt;- as.integer(ds$Cell.shape)
    ds$Marg.adhesion &lt;- as.integer(ds$Marg.adhesion)
    ds$Epith.c.size &lt;- as.integer(ds$Epith.c.size)
    ds$Bare.nuclei &lt;- as.integer(ds$Bare.nuclei)
    ds$Bl.cromatin &lt;- as.integer(ds$Bl.cromatin)
    ds$Normal.nucleoli &lt;- as.integer(ds$Normal.nucleoli)
    ds$Mitoses &lt;- as.integer(ds$Mitoses)
  } else if (name == "sonar") {
    data("Sonar")
    ds &lt;- data.frame(Sonar)
  } else if (name == "vowel") {
    data("Vowel")
    ds &lt;- data.frame(Vowel)
    ds$V1 &lt;- as.integer(ds$V1)
  } else if (name == "iono") {
    data("Ionosphere")
    ds &lt;- data.frame(Ionosphere)
    ds$V1 &lt;- as.integer(ds$V1)
    ds$V2 &lt;- NULL
  } else if (name == "vehicle") {
    data("Vehicle")
    ds &lt;- data.frame(Vehicle)
  } else if (name == "letter") {
    data("LetterRecognition")
    ds &lt;- data.frame(LetterRecognition)
    dsLabel &lt;- "lettr"
  } else if (name == "satellite") {
    data("Satellite")
    ds &lt;- data.frame(Satellite)
    dsLabel &lt;- "classes"
  } else if (name == "segment") {
    data("segmentationData")
    ds &lt;- data.frame(segmentationData)
    ds$Cell &lt;- NULL
    ds$Case &lt;- as.integer(ds$Case)
  }
  
  
  # Below regression-datasets!
  # 'label'/'dsLabel' is the target regression column!
  else if (name == "diamonds") {
    data("diamonds")
    ds &lt;- data.frame(diamonds)
    dsLabel &lt;- "price"
    
    ds$cut &lt;- as.integer(ds$cut)
    ds$color &lt;- as.integer(ds$color)
    ds$clarity &lt;- as.integer(ds$clarity)
  } else if (name == "sacramento") {
    data("Sacramento")
    ds &lt;- data.frame(Sacramento)
    dsLabel &lt;- "price"
    
    ds$zip &lt;- NULL
    ds$city &lt;- as.character(ds$city)
    ds$type &lt;- as.character(ds$type)
  } else if (name == "boston") {
    data("BostonHousing")
    ds &lt;- data.frame(BostonHousing)
    dsLabel &lt;- "ptratio"
    ds$chas &lt;- as.character(ds$chas)
  } else if (name == "midwest") {
    data("midwest")
    ds &lt;- data.frame(midwest)
    dsLabel &lt;- "percwhite"
    
    ds$PID &lt;- NULL
    ds$county &lt;- NULL
    ds$category &lt;- NULL
  } else if (name == "seals") {
    data("seals")
    ds &lt;- data.frame(seals)
    dsLabel &lt;- "delta_long"
  } else if (name == "txhousing") {
    data("txhousing")
    ds &lt;- data.frame(txhousing)
    dsLabel &lt;- "sales"
  } else if (name == "mortality") {
    data("USRegionalMortality")
    ds &lt;- data.frame(USRegionalMortality)
    dsLabel &lt;- "Rate"
    
    ds$Region &lt;- as.character(ds$Region)
    ds$Status &lt;- as.character(ds$Status)
    ds$Sex &lt;- as.character(ds$Sex)
    ds$Cause &lt;- as.character(ds$Cause)
  } else if (name == "singer") {
    data("singer")
    ds &lt;- data.frame(singer)
    dsLabel &lt;- "height"
    ds$voice.part &lt;- as.character(ds$voice.part)
  } else if (name == "pima") {
    data("PimaIndiansDiabetes")
    ds &lt;- data.frame(PimaIndiansDiabetes)
    dsLabel &lt;- "age"
    ds$diabetes &lt;- as.character(ds$diabetes)
  } else if (name == "ozone") {
    data("Ozone")
    ds &lt;- data.frame(Ozone)
    dsLabel &lt;- "V11"
    
    ds$V9 &lt;- NULL # too many NAs
    ds$V1 &lt;- as.integer(ds$V1)
    ds$V2 &lt;- as.integer(ds$V2)
    ds$V3 &lt;- as.integer(ds$V3)
  } else if (name == "faithful") {
    data("faithfuld")
    ds &lt;- data.frame(faithfuld)
    dsLabel &lt;- "density"
  }
  
  
  
  # Below non-datasets
  else if (is.data.frame(useDs)) {
    ds &lt;- useDs
    dsLabel &lt;- useLabel
  } else {
    stop(paste("Dataset is not known:", name))
  }
  
  # Only take complete rows!
  ds &lt;- ds[complete.cases(ds), ]
  
  if (nrow(ds) &gt; max_rows_dataset) {
    tempPart &lt;- createDataPartition(
      ds[[dsLabel]], p = max_rows_dataset / nrow(ds), list = F)
    ds &lt;- ds[tempPart, ]
  }
  
  part &lt;- createDataPartition(
    ds[[dsLabel]], p = ifelse(nrow(ds) &lt; 800, 0.7, 0.85), list = F)
  
  return(list(
    ds = ds,
    label = dsLabel,
    train = ds[part, ],
    valid = ds[-part, ]
  ))
}


#' Uses caret's 'bestTune', i.e., the best found hyperparameters from the
#' grid-search, and extracts the results from each fold/repeat that uses
#' these. The result is a table with the results obtained using the best
#' set of hyperparameters.
#' @param resample data.frame as obtained from a fitted model trained
#' with caret (model$resample). This should ideally be obtained using a
#' train-configuration where resample="all".
#' @param bestTune data.frame as obtained from a fitted model trained
#' with caret (model$bestTune).
#' @return data.frame a subset of 'resample', where the rows use the hyper-
#' parameters from 'bestTune'.
aggregate_caret_results &lt;- function(resample, bestTune) {
  conds &lt;- c()
  for (cName in colnames(bestTune)) {
    bt &lt;- bestTune[[cName]]
    cond &lt;- NULL
    if (is.na(bt) || is.nan(bt)) {
      n &lt;- if (is.nan(bt)) "n" else ""
      cond &lt;- paste(
        "is.na", n, "(resample$", cName, ")", sep = "")
    } else if (is.numeric(bt) &amp;&amp; (bt[1] %% 1 != 0)) {
      cond &lt;- paste(
        "(abs(resample$", cName, " - ", "bestTune$", cName, ") &lt; 1e-15)", sep = "")
    } else if (is.character(bt) || is.factor(bt)) {
      cond &lt;- paste(
        "resample$", cName, " == ",
        paste('"', bestTune[[cName]], '"', sep = ""),
        sep = ""
      )
    } else {
      cond &lt;- paste(
        "resample$", cName, " == ", "bestTune$", cName, sep = "")
    }

    conds &lt;- c(conds, cond)
  }
  
  return(resample[eval(parse(text = paste(conds, collapse = " &amp; "))), ])
}


#' Returns a list of seeds used in parallel training with caret. For
#' repeatability, we need deterministic seeds. The amount depends on
#' the amounts of hyperparamenters, and number of folds/repeats.
#' @param nh integer, the number of hyperparameters
#' @param amount integer, the number of seeds, usually this is number
#' of folds * number of repeats.
#' @param seed integer used in \code{set.seed()}. Given an identical
#' seed, this function produces the same seeds (idempotent).
#' @return list with seeds that can be used in caret's trainControl
get_seeds &lt;- function(nh, amount, seed = 42) {
  set.seed(seed)
  
  seeds &lt;- vector(mode = "list", length = amount + 1)
  for(i in 1:amount) seeds[[i]] &lt;- sample.int(.Machine$integer.max, nh)
  # For the last model:
  seeds[[amount + 1]] &lt;- sample.int(.Machine$integer.max, 1)
  return(seeds)
}</code></pre>
<p>Let’s define a function to perform grid search.</p>
<pre><code>#' modelsAndDatasets is a data.frame with columns 'model' and 'dataset'.
#' It should already match each model with the right dataset, i.e., it
#' should not have a row {nb,diamonds}, as Naive Bayes cannot regress.
#' This function does not return anything, but stores the result of each
#' model/dataset combination as CSV.
#' @param modelsAndDatasets data.frame, with the columns 'model' and
#' 'dataset'. Model needs to be acceptable for caret, and dataset needs
#' to be acceptable by @seealso \code{get_dataset()}.
#' @return void
get_other_models_results &lt;- function(modelsAndDatasets = data.frame()) {
  if (DISABLE_COMPUTATIONS) {
    return(0)
  }
  perms &lt;- modelsAndDatasets[order(modelsAndDatasets$model, modelsAndDatasets$dataset), ]
  set.seed(0xbeef42)
  perms &lt;- perms[sample(rownames(perms)), ]
  
  
  numCores &lt;- parallel::detectCores()
  numCoresNested &lt;- if (nrow(perms) &lt; numCores) numCores else max(2, numCores / 4)
  cl &lt;- parallel::makeCluster(max(2, numCores / 2), outfile = "")
  clusterExport(cl, as.list(names(.GlobalEnv)))
  registerDoSNOW(cl)
  pb &lt;- txtProgressBar(min = 0, max = nrow(perms), style = 3)
  
  
  caretModelResultsList &lt;- foreach(
    permRowIdx = rownames(perms),
    .packages = c(packages_required),
    .options.snow = list(
      progress = function(n) {
        writeLines(paste(n, Sys.time(), sep = "  --  "), con = "progress.txt")
        setTxtProgressBar(pb, n)
      }
    )
  ) %dopar% {
    idx &lt;- as.numeric(permRowIdx)
    permRow &lt;- perms[permRowIdx, ]
    dsList &lt;- get_dataset(permRow$dataset, seedMult = 1337 * idx)
    trP &lt;- nrow(dsList$train) / nrow(dsList$ds)
    isRegress &lt;- is.numeric(dsList$ds[, dsList$label])
    typeShort &lt;- if (isRegress) "r" else "c"
    isMMB &lt;- length(grep("bayesCaret", permRow$model)) &gt; 0
    
    dataName &lt;- paste("results_", typeShort, "/", permRow$model, "_", permRow$dataset, "_", typeShort, ".csv", sep = "")
    if (file.exists(dataName)) {
      return(read.csv(dataName))
    }
    
    # Workaround: The models mlpML, pam, rda do not support ordered factors
    # in the chick dataset and will fail, but we can convert them to numeric.
    if (permRow$model %in% c("mlpML", "pam", "rda") &amp;&amp; permRow$dataset == "chick") {
      dsList$ds$Chick &lt;- as.numeric(dsList$ds$Chick)
      dsList$train$Chick &lt;- as.numeric(dsList$train$Chick)
      dsList$valid$Chick &lt;- as.numeric(dsList$valid$Chick)
    }
    
    x &lt;- dsList$ds[, !(colnames(dsList$ds) %in% c(dsList$label))]
    y &lt;- dsList$ds[, dsList$label]
    
    rcvNumber &lt;- 5
    rcvRepeats &lt;- 3
    trMethod &lt;- "repeatedcv"
    tuneLength &lt;- ifelse(trMethod == "none", 1, 3)
    numHypers &lt;- nrow(if (isMMB) mmb::bayesCaret$grid(x = x, y = y) else caret::getModelInfo(
      permRow$model)[[1]]$grid(len = tuneLength, x = x, y = y))

    set.seed(idx * 23)
    trControl &lt;- caret::trainControl(
      method = trMethod, number = rcvNumber, repeats = rcvRepeats,
      p = trP, savePredictions = "all", returnResamp = "all",
      seeds = get_seeds(numHypers, rcvNumber * rcvRepeats, seed = idx * 23))
    
    clNested &lt;- makePSOCKcluster(numCoresNested)
    registerDoParallel(clNested)
    
    set.seed(idx * 371)
    timeStart &lt;- proc.time()[["elapsed"]]
    modelName &lt;- as.character(permRow$model)
    modelObj &lt;- if (isMMB) mmb::bayesCaret else modelName
    model &lt;- caret::train(x = x, y = y, method = modelObj, trControl = trControl)
    timeEnd &lt;- proc.time()[["elapsed"]]
    
    stopCluster(clNested)
    
    # Now we store 2 things:
    # - The full resample
    # - The aggregated resample (those matching bestTune)
    dataFull &lt;- model$resample
    dataFull$Model &lt;- permRow$model
    dataFull$Dataset &lt;- permRow$dataset
    dataFull$Runtime &lt;- (timeEnd - timeStart) / (rcvNumber * rcvRepeats)
    
    
    # Now the aggregated:
    dataAgg &lt;- aggregate_caret_results(dataFull, model$bestTune)
    
    
    # Rename some columns and write files:
    for (cn in colnames(model$bestTune)) {
      dataFull[[paste("hyper.", cn, sep = "")]] &lt;- dataFull[[cn]]
      if (!(cn %in% c("Model", "Dataset", "Runtime"))) {
        dataFull[[cn]] &lt;- NULL # delete renamed column
      }
      
      dataAgg[[paste("hyper.", cn, sep = "")]] &lt;- dataAgg[[cn]]
      if (!(cn %in% c("Model", "Dataset", "Runtime"))) {
        dataAgg[[cn]] &lt;- NULL
      }
    }
    
    
    dataName &lt;- paste("results_", typeShort, "/", permRow$model, "_", permRow$dataset, "_", typeShort, ".csv", sep = "")
    utils::write.csv(dataFull, dataName)
    dataName &lt;- paste("results_", typeShort, "/", permRow$model, "_", permRow$dataset, "_", typeShort, "_agg.csv", sep = "")
    utils::write.csv(dataAgg, dataName)
    
    
    return(dataFull)
  }
  
  stopCluster(cl)
  registerDoSEQ()
}</code></pre>
<div id="classification" class="section level2">
<h2 class="hasAnchor">
<a href="#classification" class="anchor"></a>Classification</h2>
<p>Here, we use the full grid as provided by <code>bayesCaret</code>. Please note that the grid and its size depends on whether we are doing classification or not.</p>
<pre><code>datasets_c &lt;- c("iris", "chick", "credit", "glass", "breast", "sonar")
modelAndData_c &lt;- expand.grid(
  model = caret_models_c,
  dataset = datasets_c,
  stringsAsFactors = FALSE)

get_other_models_results(modelAndData_c)

## [1] 0</code></pre>
</div>
<div id="regression" class="section level2">
<h2 class="hasAnchor">
<a href="#regression" class="anchor"></a>Regression</h2>
<pre><code># We set a new default regressor, to avoid NaN in sparse predictions.
mmb::setDefaultRegressor(function(data) {
  res &lt;- mmb::estimatePdf(data)$argmax
  if (is.na(res)) {
    res &lt;- median(data)
  }
  return(res)
})

datasets_r &lt;- c("mortality", "sacramento", "boston", "seals", "faithful", "diamonds")
modelAndData_r &lt;- expand.grid(
  model = caret_models_r,
  dataset = datasets_r,
  stringsAsFactors = FALSE)

get_other_models_results(modelAndData_r)

## [1] 0</code></pre>
</div>
</div>
<div id="evaluation" class="section level1">
<h1 class="hasAnchor">
<a href="#evaluation" class="anchor"></a>Evaluation</h1>
<p>In this section, we will load the results and aggregate all data, so that we can then continue with visualizations and statistical analyses. We begin by first loading the results for all other models, before continuing with our Bayesian results.</p>
<pre><code>install.packages_cond("extrafont")

## Registering fonts with R

if (.Platform$OS.type == "windows") {
  windowsFonts(Times = windowsFont("Times"))
  windowsFonts(Consolas = windowsFont("Consolas"))
}
# Was overridden by RandomForest
margin &lt;- ggplot2::margin


#' Given a ggplot2 instance, saves the plot as EPS in the figures-directory,
#' and then returns it for further processing.
#' @param ggplotInstance a gg plot
#' @param fileName character the name of the file, without the extension.
#' @param width in inches, defaults to the width of a portrait A4 (210mm)
#' @param height in inches, defaults to 10cm (~3.93in)
#' @return ggplot the instance as given, unchanged
saveAndPlotAsEPS &lt;- function(ggplotInstance, fileName, width = 2100/254, height = 1000/254) {
  f &lt;- "figures"
  if (!dir.exists(f)) {
    dir.create(f)
  }
  
  fileName &lt;- paste(f, paste(fileName, ".eps", sep = ""), sep = "/")
  ggsave(fileName, ggplotInstance,
         width = floor(width * 100) / 100,
         height = floor(height * 100) / 100,
         limitsize = F, device = cairo_pdf)
  return(ggplotInstance)
}</code></pre>
<div id="evaluation-of-the-bayes-only-models" class="section level2">
<h2 class="hasAnchor">
<a href="#evaluation-of-the-bayes-only-models" class="anchor"></a>Evaluation of the Bayes-only models</h2>
<p>In this section, we will outline the effects of various hyperparameters in our Bayesian models.</p>
<div id="load-and-aggregate-the-data" class="section level3">
<h3 class="hasAnchor">
<a href="#load-and-aggregate-the-data" class="anchor"></a>Load and aggregate the data</h3>
<p>We need to aggregate the results from each model, both for classification and regression.</p>
<pre><code># bc means bayesCaret, c=classification
results_bc_c &lt;- do.call(rbind, lapply(datasets_c, function(d) {
  csv &lt;- read.csv(paste("results_c/bayesCaret_", d, "_c.csv", sep = ""))
  csv$X &lt;- NULL
  csv$Model &lt;- NULL
  return(csv)
}))

(ggplot(results_bc_c, aes(x=Dataset, y=Accuracy)) +
  labs(subtitle = "Accuracy of full and simple classification.") +
  geom_boxplot(color="black") +
  facet_wrap(hyper.simple ~ ., labeller = label_both) +
  theme_bw() +
  theme(
    text = element_text(family="Consolas"),
    axis.text.x = element_text(angle = 45, margin = margin(t=10), hjust = .66),
    axis.title.x = element_blank(), strip.background = element_rect(fill="#dfdfdf"),
    axis.title.y = element_text(margin = margin(r=10)),
    legend.text = element_text(size = 8),
    strip.text = element_text(color="black"))
) %&gt;% saveAndPlotAsEPS("Bayes-all-datasets_Acc")</code></pre>
<p><img src="hyperparameters_files/figure-markdown_strict/unnamed-chunk-10-1.png"></p>
<pre><code># Now let's do the same, for Kappa
(ggplot(results_bc_c, aes(x=Dataset, y=Kappa)) +
  labs(subtitle = "Kappa of full and simple classification.") +
  geom_boxplot(color="black") +
  facet_wrap(hyper.simple ~ ., labeller = label_both) +
  theme_bw() +
  ylim(-.1, 1) + # For some reason, some results have a negative Kappa..
  theme(
    text = element_text(family="Consolas"),
    axis.text.x = element_text(angle = 45, margin = margin(t=10), hjust = .66),
    axis.title.x = element_blank(), strip.background = element_rect(fill="#dfdfdf"),
    axis.title.y = element_text(margin = margin(r=10)),
    legend.text = element_text(size = 8),
    strip.text = element_text(color="black"))
) %&gt;% saveAndPlotAsEPS("Bayes-all-datasets_Kappa")

## Warning: Removed 226 rows containing non-finite values (stat_boxplot).

## Warning: Removed 226 rows containing non-finite values (stat_boxplot).</code></pre>
<p><img src="hyperparameters_files/figure-markdown_strict/unnamed-chunk-10-2.png"></p>
</div>
<div id="evaluation-and-comparison-to-other-models" class="section level3">
<h3 class="hasAnchor">
<a href="#evaluation-and-comparison-to-other-models" class="anchor"></a>Evaluation and comparison to other models</h3>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#grid-search">Grid search</a><ul class="nav nav-pills nav-stacked">
<li><a href="#classification">Classification</a></li>
      <li><a href="#regression">Regression</a></li>
      </ul>
</li>
      <li>
<a href="#evaluation">Evaluation</a><ul class="nav nav-pills nav-stacked">
<li><a href="#evaluation-of-the-bayes-only-models">Evaluation of the Bayes-only models</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Sebastian Hönel.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
